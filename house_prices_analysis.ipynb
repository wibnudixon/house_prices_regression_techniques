{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ec2421e",
   "metadata": {},
   "source": [
    "# House Prices Regression Techniques\n",
    "\n",
    "## Project Overview\n",
    "This notebook contains the complete analysis and modeling workflow for predicting house prices using the Ames Housing dataset.\n",
    "\n",
    "**Goal:** Predict the sales price for each house in the test set.\n",
    "\n",
    "**Evaluation Metric:** RMSE between the logarithm of predicted and observed sales prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8300516",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e1b3dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d17a40",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "Load the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b386e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1460, 81)\n",
      "Test data shape: (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "train_df = pd.read_csv('Data/train.csv')\n",
    "test_df = pd.read_csv('Data/test.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b8f4f",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 3.1 First Look at the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165eb975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49610d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b48f6",
   "metadata": {},
   "source": [
    "### 3.2 Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable statistics\n",
    "print(\"SalePrice Statistics:\")\n",
    "print(train_df['SalePrice'].describe())\n",
    "print(f\"\\nSkewness: {train_df['SalePrice'].skew()}\")\n",
    "print(f\"Kurtosis: {train_df['SalePrice'].kurtosis()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc3358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target variable distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Original distribution\n",
    "axes[0].hist(train_df['SalePrice'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Sale Price')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Sale Prices')\n",
    "\n",
    "# Log-transformed distribution\n",
    "axes[1].hist(np.log1p(train_df['SalePrice']), bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].set_xlabel('Log(Sale Price)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution of Log-Transformed Sale Prices')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e826cc",
   "metadata": {},
   "source": [
    "### 3.3 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9691cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - Missing Values:\n",
      "Your selected dataframe has 81 columns.\n",
      "There are 19 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>1453</td>\n",
       "      <td>99.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>1406</td>\n",
       "      <td>96.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>1369</td>\n",
       "      <td>93.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>1179</td>\n",
       "      <td>80.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>872</td>\n",
       "      <td>59.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>690</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>259</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>81</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>81</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>81</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>81</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>81</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>38</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>38</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>37</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>37</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>37</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missing Values  % of Total Values\n",
       "PoolQC                  1453               99.5\n",
       "MiscFeature             1406               96.3\n",
       "Alley                   1369               93.8\n",
       "Fence                   1179               80.8\n",
       "MasVnrType               872               59.7\n",
       "FireplaceQu              690               47.3\n",
       "LotFrontage              259               17.7\n",
       "GarageType                81                5.5\n",
       "GarageYrBlt               81                5.5\n",
       "GarageFinish              81                5.5\n",
       "GarageQual                81                5.5\n",
       "GarageCond                81                5.5\n",
       "BsmtExposure              38                2.6\n",
       "BsmtFinType2              38                2.6\n",
       "BsmtQual                  37                2.5\n",
       "BsmtCond                  37                2.5\n",
       "BsmtFinType1              37                2.5\n",
       "MasVnrArea                 8                0.5\n",
       "Electrical                 1                0.1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate missing values\n",
    "def missing_values_table(df):\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns={0: 'Missing Values', 1: '% of Total Values'})\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "    print(f\"Your selected dataframe has {df.shape[1]} columns.\\n\"\n",
    "          f\"There are {mis_val_table_ren_columns.shape[0]} columns that have missing values.\")\n",
    "    return mis_val_table_ren_columns\n",
    "\n",
    "# Display missing values for training data\n",
    "print(\"Training Data - Missing Values:\")\n",
    "missing_train = missing_values_table(train_df)\n",
    "missing_train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56abdf35",
   "metadata": {},
   "source": [
    "### 3.4 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4debf8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical features: 36\n",
      "Number of categorical features: 43\n",
      "\n",
      "Numerical features: ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2']...\n",
      "\n",
      "Categorical features: ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1']...\n"
     ]
    }
   ],
   "source": [
    "# Separate numerical and categorical features\n",
    "numerical_features = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove Id and SalePrice from features\n",
    "if 'Id' in numerical_features:\n",
    "    numerical_features.remove('Id')\n",
    "if 'SalePrice' in numerical_features:\n",
    "    numerical_features.remove('SalePrice')\n",
    "\n",
    "print(f\"Number of numerical features: {len(numerical_features)}\")\n",
    "print(f\"Number of categorical features: {len(categorical_features)}\")\n",
    "print(f\"\\nNumerical features: {numerical_features[:10]}...\")\n",
    "print(f\"\\nCategorical features: {categorical_features[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301a15b8",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "In this section, we'll prepare the data for modeling by:\n",
    "- Combining train and test data for consistent preprocessing\n",
    "- Handling missing values strategically\n",
    "- Creating new features\n",
    "- Encoding categorical variables\n",
    "- Scaling numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64886822",
   "metadata": {},
   "source": [
    "### 4.1 Combine Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f8f0367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (2919, 79)\n",
      "Training samples: 1460\n",
      "Test samples: 1459\n"
     ]
    }
   ],
   "source": [
    "# Save the target variable\n",
    "y_train = train_df['SalePrice'].copy()\n",
    "\n",
    "# Save test IDs for submission\n",
    "test_ids = test_df['Id'].copy()\n",
    "\n",
    "# Drop Id and SalePrice from train\n",
    "train_df = train_df.drop(['Id', 'SalePrice'], axis=1)\n",
    "test_df = test_df.drop(['Id'], axis=1)\n",
    "\n",
    "# Store the number of training samples\n",
    "n_train = train_df.shape[0]\n",
    "\n",
    "# Combine train and test for consistent preprocessing\n",
    "all_data = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"Combined dataset shape: {all_data.shape}\")\n",
    "print(f\"Training samples: {n_train}\")\n",
    "print(f\"Test samples: {all_data.shape[0] - n_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b533070",
   "metadata": {},
   "source": [
    "### 4.2 Handle Missing Values\n",
    "\n",
    "We'll handle missing values based on the data description and domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5561c06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with missing values: 34\n",
      "\n",
      "Top 10 features with missing values:\n",
      "             Missing Count  Percentage\n",
      "PoolQC                2909   99.657417\n",
      "MiscFeature           2814   96.402878\n",
      "Alley                 2721   93.216855\n",
      "Fence                 2348   80.438506\n",
      "MasVnrType            1766   60.500171\n",
      "FireplaceQu           1420   48.646797\n",
      "LotFrontage            486   16.649538\n",
      "GarageQual             159    5.447071\n",
      "GarageYrBlt            159    5.447071\n",
      "GarageCond             159    5.447071\n"
     ]
    }
   ],
   "source": [
    "# Check missing values in combined dataset\n",
    "missing_data = all_data.isnull().sum()\n",
    "missing_data = missing_data[missing_data > 0].sort_values(ascending=False)\n",
    "missing_percent = (missing_data / len(all_data)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({'Missing Count': missing_data, 'Percentage': missing_percent})\n",
    "print(f\"Features with missing values: {len(missing_df)}\")\n",
    "print(\"\\nTop 10 features with missing values:\")\n",
    "print(missing_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bfe547d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Remaining missing values: 0\n",
      "Missing value handling complete!\n"
     ]
    }
   ],
   "source": [
    "# For features where NA means \"None\" or \"No feature\"\n",
    "none_cols = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu',\n",
    "             'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "             'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "             'MasVnrType']\n",
    "\n",
    "for col in none_cols:\n",
    "    if col in all_data.columns:\n",
    "        all_data[col] = all_data[col].fillna('None')\n",
    "\n",
    "# For garage year built, fill with 0 (no garage)\n",
    "if 'GarageYrBlt' in all_data.columns:\n",
    "    all_data['GarageYrBlt'] = all_data['GarageYrBlt'].fillna(0)\n",
    "\n",
    "# For basement and garage related numerical features, fill with 0\n",
    "zero_cols = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "             'BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'GarageArea',\n",
    "             'MasVnrArea']\n",
    "\n",
    "for col in zero_cols:\n",
    "    if col in all_data.columns:\n",
    "        all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "# For LotFrontage, fill with median by neighborhood\n",
    "if 'LotFrontage' in all_data.columns:\n",
    "    all_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].transform(\n",
    "        lambda x: x.fillna(x.median()))\n",
    "\n",
    "# For other categorical features, fill with mode\n",
    "categorical_cols = all_data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if all_data[col].isnull().sum() > 0:\n",
    "        all_data[col] = all_data[col].fillna(all_data[col].mode()[0])\n",
    "\n",
    "# For remaining numerical features, fill with median\n",
    "numerical_cols = all_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "for col in numerical_cols:\n",
    "    if all_data[col].isnull().sum() > 0:\n",
    "        all_data[col] = all_data[col].fillna(all_data[col].median())\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(f\"\\nRemaining missing values: {all_data.isnull().sum().sum()}\")\n",
    "print(\"Missing value handling complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21170b4a",
   "metadata": {},
   "source": [
    "### 4.3 Feature Engineering\n",
    "\n",
    "Create new features that might be useful for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20385f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete!\n",
      "New dataset shape: (2919, 90)\n"
     ]
    }
   ],
   "source": [
    "# Total square footage\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "\n",
    "# Total bathrooms\n",
    "all_data['TotalBath'] = (all_data['FullBath'] + (0.5 * all_data['HalfBath']) +\n",
    "                         all_data['BsmtFullBath'] + (0.5 * all_data['BsmtHalfBath']))\n",
    "\n",
    "# Total porch square footage\n",
    "all_data['TotalPorchSF'] = (all_data['OpenPorchSF'] + all_data['3SsnPorch'] +\n",
    "                            all_data['EnclosedPorch'] + all_data['ScreenPorch'] +\n",
    "                            all_data['WoodDeckSF'])\n",
    "\n",
    "# Has pool\n",
    "all_data['HasPool'] = (all_data['PoolArea'] > 0).astype(int)\n",
    "\n",
    "# Has 2nd floor\n",
    "all_data['Has2ndFloor'] = (all_data['2ndFlrSF'] > 0).astype(int)\n",
    "\n",
    "# Has garage\n",
    "all_data['HasGarage'] = (all_data['GarageArea'] > 0).astype(int)\n",
    "\n",
    "# Has basement\n",
    "all_data['HasBsmt'] = (all_data['TotalBsmtSF'] > 0).astype(int)\n",
    "\n",
    "# Has fireplace\n",
    "all_data['HasFireplace'] = (all_data['Fireplaces'] > 0).astype(int)\n",
    "\n",
    "# House age\n",
    "all_data['HouseAge'] = all_data['YrSold'] - all_data['YearBuilt']\n",
    "\n",
    "# Years since remodel\n",
    "all_data['YearsSinceRemod'] = all_data['YrSold'] - all_data['YearRemodAdd']\n",
    "\n",
    "# Is new house (sold in the year it was built)\n",
    "all_data['IsNew'] = (all_data['YearBuilt'] == all_data['YrSold']).astype(int)\n",
    "\n",
    "print(\"Feature engineering complete!\")\n",
    "print(f\"New dataset shape: {all_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b46ed8",
   "metadata": {},
   "source": [
    "### 4.4 Handle Skewed Features\n",
    "\n",
    "Log-transform highly skewed numerical features to make them more normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ece530d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of skewed features: 29\n",
      "\n",
      "Top 10 most skewed features:\n",
      "MiscVal          21.947195\n",
      "PoolArea         16.898328\n",
      "HasPool          14.884318\n",
      "LotArea          12.822431\n",
      "LowQualFinSF     12.088761\n",
      "3SsnPorch        11.376065\n",
      "IsNew             4.712237\n",
      "KitchenAbvGr      4.302254\n",
      "BsmtFinSF2        4.146143\n",
      "EnclosedPorch     4.003891\n",
      "dtype: float64\n",
      "\n",
      "Skewness correction applied!\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "# Get numerical features\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "\n",
    "# Calculate skewness\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "\n",
    "# Select features with skewness > 0.75\n",
    "skewed_feats = skewed_feats[abs(skewed_feats) > 0.75]\n",
    "\n",
    "print(f\"Number of skewed features: {len(skewed_feats)}\")\n",
    "print(\"\\nTop 10 most skewed features:\")\n",
    "print(skewed_feats.sort_values(ascending=False).head(10))\n",
    "\n",
    "# Apply log1p transformation to reduce skewness\n",
    "for feat in skewed_feats.index:\n",
    "    all_data[feat] = np.log1p(all_data[feat])\n",
    "\n",
    "print(\"\\nSkewness correction applied!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614bb1d6",
   "metadata": {},
   "source": [
    "### 4.5 Encode Categorical Variables\n",
    "\n",
    "Convert categorical features to numerical using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b822b022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after encoding: (2919, 270)\n",
      "Number of features: 270\n"
     ]
    }
   ],
   "source": [
    "# Get dummy variables for categorical features\n",
    "all_data = pd.get_dummies(all_data, drop_first=True)\n",
    "\n",
    "print(f\"Dataset shape after encoding: {all_data.shape}\")\n",
    "print(f\"Number of features: {all_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c1475b",
   "metadata": {},
   "source": [
    "### 4.6 Split Back to Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "104c31fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1460, 270)\n",
      "X_test shape: (1459, 270)\n",
      "y_train shape: (1460,)\n",
      "y_train_log shape: (1460,)\n",
      "\n",
      "Data preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "# Split back into train and test sets\n",
    "X_train = all_data[:n_train].copy()\n",
    "X_test = all_data[n_train:].copy()\n",
    "\n",
    "# Also transform the target variable (log transformation)\n",
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_train_log shape: {y_train_log.shape}\")\n",
    "print(\"\\nData preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092cab75",
   "metadata": {},
   "source": [
    "### 4.7 Preprocessing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b32fe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA PREPROCESSING SUMMARY\n",
      "============================================================\n",
      "\n",
      "Original features: 79\n",
      "After feature engineering: 90\n",
      "After one-hot encoding: 270\n",
      "\n",
      "Training samples: 1460\n",
      "Test samples: 1459\n",
      "\n",
      "Missing values handled: ✓\n",
      "Skewed features corrected: ✓\n",
      "Categorical encoding: ✓\n",
      "Target transformation (log): ✓\n",
      "\n",
      "============================================================\n",
      "Ready for modeling!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DATA PREPROCESSING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nOriginal features: 79\")\n",
    "print(f\"After feature engineering: 90\")\n",
    "print(f\"After one-hot encoding: {X_train.shape[1]}\")\n",
    "print(f\"\\nTraining samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "print(f\"\\nMissing values handled: ✓\")\n",
    "print(f\"Skewed features corrected: ✓\")\n",
    "print(f\"Categorical encoding: ✓\")\n",
    "print(f\"Target transformation (log): ✓\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Ready for modeling!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc323c8d",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "*To be continued...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f94806",
   "metadata": {},
   "source": [
    "## 6. Model Development\n",
    "\n",
    "*To be continued...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dedc301",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "\n",
    "*To be continued...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad27d4",
   "metadata": {},
   "source": [
    "## 8. Generate Predictions\n",
    "\n",
    "*To be continued...*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g_stck_ts-kSKo1Eb0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

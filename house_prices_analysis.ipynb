{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f5bf65",
   "metadata": {},
   "source": [
    "# House Prices Regression Techniques\n",
    "\n",
    "**Goal:** Predict house sale prices using 79 explanatory variables\n",
    "\n",
    "**Evaluation Metric:** RMSE between log of predicted and observed prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6160495e",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import skew\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d01b87",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_df = pd.read_csv('Data/train.csv')\n",
    "test_df = pd.read_csv('Data/test.csv')\n",
    "\n",
    "print(f\"Train: {train_df.shape}\")\n",
    "print(f\"Test: {test_df.shape}\")\n",
    "\n",
    "# Display first few rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0713e069",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d5f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(train_df['SalePrice'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Sale Price Distribution')\n",
    "axes[0].set_xlabel('Sale Price')\n",
    "\n",
    "axes[1].hist(np.log1p(train_df['SalePrice']), bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].set_title('Log-Transformed Sale Price')\n",
    "axes[1].set_xlabel('Log(Sale Price)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Skewness: {train_df['SalePrice'].skew():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "def check_missing(df, name='Dataset'):\n",
    "    missing = df.isnull().sum()\n",
    "    missing = missing[missing > 0].sort_values(ascending=False)\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    \n",
    "    result = pd.DataFrame({'Missing': missing, 'Percent': missing_pct})\n",
    "    print(f\"\\n{name}: {len(result)} features with missing values\")\n",
    "    return result\n",
    "\n",
    "missing_train = check_missing(train_df, 'Training Data')\n",
    "missing_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b5d574",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17a9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save target and IDs\n",
    "y_train = train_df['SalePrice'].copy()\n",
    "test_ids = test_df['Id'].copy()\n",
    "\n",
    "# Drop ID and target\n",
    "train_df = train_df.drop(['Id', 'SalePrice'], axis=1)\n",
    "test_df = test_df.drop(['Id'], axis=1)\n",
    "\n",
    "# Combine for consistent preprocessing\n",
    "n_train = len(train_df)\n",
    "all_data = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"Combined data: {all_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "\n",
    "# 1. Features where NA means \"None\"\n",
    "none_features = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu',\n",
    "                 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "                 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "                 'MasVnrType']\n",
    "\n",
    "for col in none_features:\n",
    "    if col in all_data.columns:\n",
    "        all_data[col] = all_data[col].fillna('None')\n",
    "\n",
    "# 2. Numerical features to fill with 0\n",
    "zero_features = ['GarageYrBlt', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "                 'BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'GarageArea', 'MasVnrArea']\n",
    "\n",
    "for col in zero_features:\n",
    "    if col in all_data.columns:\n",
    "        all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "# 3. LotFrontage: fill with median by neighborhood\n",
    "if 'LotFrontage' in all_data.columns:\n",
    "    all_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].transform(\n",
    "        lambda x: x.fillna(x.median()))\n",
    "\n",
    "# 4. Other categorical: fill with mode\n",
    "for col in all_data.select_dtypes(include=['object']).columns:\n",
    "    if all_data[col].isnull().sum() > 0:\n",
    "        all_data[col] = all_data[col].fillna(all_data[col].mode()[0])\n",
    "\n",
    "# 5. Remaining numerical: fill with median\n",
    "for col in all_data.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    if all_data[col].isnull().sum() > 0:\n",
    "        all_data[col] = all_data[col].fillna(all_data[col].median())\n",
    "\n",
    "print(f\"Remaining missing values: {all_data.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96735ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "all_data['TotalBath'] = (all_data['FullBath'] + 0.5 * all_data['HalfBath'] +\n",
    "                         all_data['BsmtFullBath'] + 0.5 * all_data['BsmtHalfBath'])\n",
    "all_data['TotalPorchSF'] = (all_data['OpenPorchSF'] + all_data['3SsnPorch'] +\n",
    "                            all_data['EnclosedPorch'] + all_data['ScreenPorch'] +\n",
    "                            all_data['WoodDeckSF'])\n",
    "all_data['HouseAge'] = all_data['YrSold'] - all_data['YearBuilt']\n",
    "all_data['YearsSinceRemod'] = all_data['YrSold'] - all_data['YearRemodAdd']\n",
    "all_data['HasPool'] = (all_data['PoolArea'] > 0).astype(int)\n",
    "all_data['Has2ndFloor'] = (all_data['2ndFlrSF'] > 0).astype(int)\n",
    "all_data['HasGarage'] = (all_data['GarageArea'] > 0).astype(int)\n",
    "all_data['HasBsmt'] = (all_data['TotalBsmtSF'] > 0).astype(int)\n",
    "all_data['HasFireplace'] = (all_data['Fireplaces'] > 0).astype(int)\n",
    "\n",
    "print(f\"‚úì Features engineered: {all_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle skewed features\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "skewed_feats = skewed_feats[abs(skewed_feats) > 0.75]\n",
    "\n",
    "print(f\"Skewed features: {len(skewed_feats)}\")\n",
    "\n",
    "for feat in skewed_feats.index:\n",
    "    all_data[feat] = np.log1p(all_data[feat])\n",
    "\n",
    "print(\"‚úì Skewness corrected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "all_data = pd.get_dummies(all_data, drop_first=True)\n",
    "\n",
    "print(f\"‚úì Encoded features: {all_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split back to train and test\n",
    "X_train = all_data[:n_train].copy()\n",
    "X_test = all_data[n_train:].copy()\n",
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(\"\\n‚úì Preprocessing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873a0892",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d11889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def rmse_cv(model, X, y, cv=5):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, \n",
    "                                     scoring=\"neg_mean_squared_error\", cv=cv))\n",
    "    return rmse\n",
    "\n",
    "def train_and_evaluate(model, X, y, name):\n",
    "    scores = rmse_cv(model, X, y)\n",
    "    print(f\"{name:20s} | CV RMSE: {scores.mean():.6f} (+/- {scores.std():.6f})\")\n",
    "    return scores.mean(), scores.std()\n",
    "\n",
    "print(\"‚úì Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca9a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and compare models\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "models = {\n",
    "    'Ridge': Ridge(alpha=10.0, random_state=42),\n",
    "    'Lasso': Lasso(alpha=0.0005, random_state=42, max_iter=10000),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=15, \n",
    "                                           min_samples_split=5, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=300, learning_rate=0.05,\n",
    "                                                   max_depth=4, min_samples_split=5,\n",
    "                                                   random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    mean_score, std_score = train_and_evaluate(model, X_train, y_train_log, name)\n",
    "    results[name] = (mean_score, std_score)\n",
    "\n",
    "# Find best model\n",
    "best_model_name = min(results, key=lambda x: results[x][0])\n",
    "print(f\"\\n‚úì Best Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d28f4cf",
   "metadata": {},
   "source": [
    "## 6. Final Model & Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6079e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on full training data\n",
    "final_model = models[best_model_name]\n",
    "final_model.fit(X_train, y_train_log)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_log = final_model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "print(f\"‚úì Final model trained: {best_model_name}\")\n",
    "print(f\"\\nPrediction Statistics:\")\n",
    "print(f\"  Mean: ${y_pred.mean():,.2f}\")\n",
    "print(f\"  Median: ${np.median(y_pred):,.2f}\")\n",
    "print(f\"  Range: ${y_pred.min():,.2f} - ${y_pred.max():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e722e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_ids,\n",
    "    'SalePrice': y_pred\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"‚úì Submission file created: submission.csv\")\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144fa335",
   "metadata": {},
   "source": [
    "## 7. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131635c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Model scores\n",
    "model_names = list(results.keys())\n",
    "mean_scores = [results[m][0] for m in model_names]\n",
    "std_scores = [results[m][1] for m in model_names]\n",
    "\n",
    "colors = ['#4ECDC4' if m == best_model_name else '#95E1D3' for m in model_names]\n",
    "axes[0].barh(model_names, mean_scores, xerr=std_scores, color=colors, alpha=0.8, \n",
    "             edgecolor='black', linewidth=2)\n",
    "axes[0].set_xlabel('CV RMSE')\n",
    "axes[0].set_title('Model Performance Comparison', fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Feature importance (if available)\n",
    "if hasattr(final_model, 'feature_importances_'):\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': final_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False).head(15)\n",
    "    \n",
    "    axes[1].barh(range(len(importance)), importance['importance'], \n",
    "                 color='#FF6B6B', alpha=0.8, edgecolor='black', linewidth=2)\n",
    "    axes[1].set_yticks(range(len(importance)))\n",
    "    axes[1].set_yticklabels(importance['feature'], fontsize=9)\n",
    "    axes[1].set_xlabel('Importance')\n",
    "    axes[1].set_title('Top 15 Feature Importances', fontweight='bold')\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].grid(axis='x', alpha=0.3)\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'Feature importance\\nnot available for this model', \n",
    "                ha='center', va='center', fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "\n",
    "plt.suptitle('üè† House Prices Prediction - Results', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bca7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\" * 70)\n",
    "print(\"PROJECT COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n‚úì Training samples: {len(X_train)}\")\n",
    "print(f\"‚úì Test predictions: {len(y_pred)}\")\n",
    "print(f\"‚úì Features: {X_train.shape[1]}\")\n",
    "print(f\"‚úì Best model: {best_model_name}\")\n",
    "print(f\"‚úì CV RMSE: {results[best_model_name][0]:.6f}\")\n",
    "print(f\"\\nüìÅ Submission file: submission.csv\")\n",
    "print(\"\\nüéØ Next steps:\")\n",
    "print(\"   1. Upload submission.csv to Kaggle\")\n",
    "print(\"   2. Review leaderboard score\")\n",
    "print(\"   3. Iterate with hyperparameter tuning\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
